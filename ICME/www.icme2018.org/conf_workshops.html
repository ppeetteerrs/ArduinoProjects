<!DOCTYPE html>
<html>
<head>
<meta content='text/html; charset=UTF-8' http-equiv='Content-Type'>
<meta content='width=device-width, initial-scale=1.0' name='viewport'>
<title>ICME 2018 - IEEE International Conference on Multimedia and Expo</title>
<meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="OByNVlm0P2P6d/O6ufksjfWZeHb215Orw7vHhgySVVH7fCOiARdBSDPZxxeoSwzDN95sI+nHiXZhSy1+LL9lGw==" />
<link rel="stylesheet" media="all" href="assets/application-0b4d324e64e1cc8ab75b68ca9009fb7e70470548b5a10afa23d7399bf036eab5.css" data-turbolinks-track="reload" />
<link rel="stylesheet" media="all" href="assets/main-70d3cec8b28e648af8d2edc5934d31df73d3da976480e47a106310a689cf6b9b.css" data-turbolinks-track="reload" />
<script src="assets/application-2dda1d80fbadc9e1647d52ff7f0e8da2992b9d11a9d991344af39542f5ddec5e.js" data-turbolinks-track="reload"></script>
<link rel="stylesheet" media="screen" href="https://fonts.googleapis.com/css?family=Lato" />
</head>
<body>
<nav class='navbar navbar-default navbar-fixed-top'>
<div class='container-fluid'>
<div class='navbar-header'>
<button class='navbar-toggle collapsed' data-target='#sitenav' data-toggle='collapse' type='button'>
<span class='icon-bar'></span>
<span class='icon-bar'></span>
<span class='icon-bar'></span>
</button>
<a class='navbar-brand' href='index.html'>ICME 2018</a>
</div>
<div class='collapse navbar-collapse pull-right' id='sitenav'>
<ul class='nav navbar-nav'>
<li class='dropdown '>
<a class='dropdown-toggle' data-toggle='dropdown' href='conf_workshops.html#' role='button'>
General
<span class='caret'></span>
</a>
<ul class='dropdown-menu dropdown-menu-right'>
<li>
<a href='organizing_committee.html'>Organizing Committee</a>
</li>
<li>
<a href='important_dates.html'>Important Dates</a>
</li>
<li>
<a href='contributing_volunteers.html'>Contributing Volunteers</a>
</li>
</ul>
</li>


<li class='dropdown '>
<a class='dropdown-toggle' data-toggle='dropdown' href='conf_workshops.html#' role='button'>
Calls
<span class='caret'></span>
</a>
<ul class='dropdown-menu dropdown-menu-right'>
<li>
<a href='paper.html'>Call for Papers</a>
</li>
<li>
<a href='workshop.html'>Call for Workshops</a>
</li>
<li>
<a href='tutorial.html'>Call for Tutorials</a>
</li>
<li>
<a href='special_session.html'>Call for Special Session</a>
</li>
<li>
<a href='panel.html'>Call for Panels</a>
</li>
<li>
<a href='demo.html'>Call for Demonstrations</a>
</li>
<li>
<a href='expo.html'>Call for Hands-on Expo</a>
</li>
<li>
<a href='grand_challenge.html'>Call for Grand Challenges</a>
</li>
<li>
<a href='student_participation.html'>Call for Student Program Participation</a>
</li>
<li>
<a href='industry_track_papers.html'>Call for Industry/Application Track Papers</a>
</li>
<li>
<a href='sponsorship.html'>Call for Sponsorship</a>
</li>
<li>
<a href='presentation.html'>Call for Presentation of T-MM Papers</a>
</li>
</ul>
</li>


<li class='dropdown active'>
<a class='dropdown-toggle' data-toggle='dropdown' href='conf_workshops.html#' role='button'>
Conference
<span class='caret'></span>
</a>
<ul class='dropdown-menu dropdown-menu-right'>
<li>
<a href='conf_glance.html'>At a Glance</a>
</li>
<li>
<a href='conf_schedule.html'>Schedule</a>
</li>
<li>
<a href='conf_plenary.html'>Plenary Talks</a>
</li>
<li>
<a href='conf_papers.html'>Papers</a>
</li>
<li class='active'>
<a class='anchor-nolink' href='conf_workshops.html#'>Workshops</a>
</li>
<li>
<a href='conf_tutorials.html'>Tutorials</a>
</li>
<li>
<a href='conf_sessions.html'>Special Sessions</a>
</li>
<li>
<a href='conf_panels.html'>Panels</a>
</li>
<li>
<a href='conf_demo.html'>Demonstrations</a>
</li>
<li>
<a href='conf_challenges.html'>Grand Challenges</a>
</li>
<li>
<a href='conf_students.html'>Student Program</a>
</li>
<li>
<a href='conf_industry.html'>Industry Forum</a>
</li>
<li>
<a href='conf_expo.html'>Hands-on Expo</a>
</li>
<li>
<a href='conf_awards.html'>Awards</a>
</li>
<li>
<a href='https://goo.gl/forms/nAE0ddGOKzNX3Gom2' target='_survey'>
Survey
<span class='glyphicon glyphicon-new-window'></span>
</a>
</li>
</ul>
</li>


<li class='dropdown '>
<a class='dropdown-toggle' data-toggle='dropdown' href='conf_workshops.html#' role='button'>
Industry
<span class='caret'></span>
</a>
<ul class='dropdown-menu dropdown-menu-right'>
<li>
<a href='industry_track_papers.html'>Call for Industry Track Papers</a>
</li>
<li>
<a href='sponsorship.html'>Call for Sponsorship</a>
</li>
<li>
<a href='conf_industry.html'>Industry Forum</a>
</li>
<li>
<a href='sponsors.html'>Sponsors</a>
</li>
</ul>
</li>


<!-- - items = { author_info: 'Author Information and Submission Instructions', author_camera_ready: 'Camera-ready Submission', author_presentation_guide: 'Presentation Guidelines', copyright: 'Copyright Publication'} -->
<li class='dropdown '>
<a class='dropdown-toggle' data-toggle='dropdown' href='conf_workshops.html#' role='button'>
Authors
<span class='caret'></span>
</a>
<ul class='dropdown-menu dropdown-menu-right'>
<li>
<a href='author_info.html'>Author Information and Submission Instructions</a>
</li>
<li>
<a href='author_camera_ready.html'>Camera-ready Submission</a>
</li>
<li>
<a href='author_presentation_guide.html'>Presentation Guidelines</a>
</li>
</ul>
</li>


<li class='dropdown '>
<a class='dropdown-toggle' data-toggle='dropdown' href='conf_workshops.html#' role='button'>
Students
<span class='caret'></span>
</a>
<ul class='dropdown-menu dropdown-menu-right'>
<li>
<a href='student_participation.html'>Call for Student Program Participation</a>
</li>
<li>
<a href='grand_challenge.html'>Call for Grand Challenges</a>
</li>
<li>
<a href='student_dinner_industry_sponsors.html'>Student Dinner Industry Sponsors</a>
</li>
</ul>
</li>


<!-- - items = { registration_desk: 'Registration Desk', registration: { name: 'Registration', link: 'http://www.cvent.com/d/1tq5y4', target: '_cvent' }, visa: 'Visa Information', venue: 'Venue and Travel', local: 'Local Information', accommodations: 'Accommodations', attractions: 'San Diego Attractions', social: 'Social Events'} -->
<li class='dropdown '>
<a class='dropdown-toggle' data-toggle='dropdown' href='conf_workshops.html#' role='button'>
Attendees
<span class='caret'></span>
</a>
<ul class='dropdown-menu dropdown-menu-right'>
<li>
<a href='http://www.cvent.com/d/1tq5y4' target='_cvent'>
Registration
<span class='glyphicon glyphicon-new-window'></span>
</a>
</li>
<li>
<a href='https://book.passkey.com/event/49045467/owner/12331/landing' target='_hotel'>
Hotel Reservation
<span class='glyphicon glyphicon-new-window'></span>
</a>
</li>
<li>
<a href='visa.html'>Visa Information</a>
</li>
<li>
<a href='venue.html'>Venue and Travel</a>
</li>
<li>
<a href='accommodations.html'>Accommodations</a>
</li>
<li>
<a href='attractions.html'>San Diego Attractions</a>
</li>
<li>
<a href='transportation.html'>San Diego Transportation</a>
</li>
<li>
<a href='social.html'>Social Events</a>
</li>
</ul>
</li>


</ul>
</div>
</div>
</nav>
<div class='container-fluid' id='main-content'>
<h1>Workshops</h1>
<a href='icme2018_program_guide.pdf'>
<div class='alert alert-warning text-center' style='padding: 32px'>
<div class='glyphicon glyphicon-book' style='font-size: 64px'></div>
<div style='font-size: 24px'>Download Program Guide</div>
</div>
</a>
<div class='panel-group' id='accordion'>
<div class='panel panel-primary'>
<div class='panel-heading'>
<h4 class='panel-title'>
<a data-parent='#accordion' data-toggle='collapse' href='conf_workshops.html#workshop-hot3d'>
Hot Topics in 3D Multimedia
</a>
<span class='glyphicon glyphicon-link pull-right clickable-workshop-link' ldata='workshop-hot3d'></span>
</h4>
</div>
<div class='panel-collapse collapse' id='workshop-hot3d'>
<div class='panel-body'>
<h4 class='specsess-heading'>Overview</h4>
<p>The 3D community continues to innovate and evolve, with greater focus on enabling augmented reality and virtual reality (AR/VR/MR) experiences. There have been amazing breakthroughs on the capture and acquisition in recent years, with the introduction of microlens camera arrays and the growing momentum behind large-scale multi-camera arrays, as well as 360-degree video and depth sensing devices. Display technology continues to advance as the emergence of head-mounted displays gain in popularity. The widespread increase in computational power has allowed an ever-increasing realism in 3D scene generation. Additionally, 3D audio has the potential to add to the immersive experience through surround sound and realistic sound field rendering.</p>
<p>While appropriate venues for presenting research at advanced stages are plentiful, the 3D multimedia community needs an appropriate venue for receiving feedback during early or initial stages of the development of radical and potentially disruptive technologies. This is the void that Hot3D tries to fill.</p>
<h4 class='specsess-heading'>Scope & Format</h4>
<p>Papers in all areas of Multimedia 3D are solicited. Early stage or preliminary results from potentially disruptive technology is particularly encouraged. Full papers (up to 6 pages) will be published in the ICME 2018 proceedings.</p>
<p>Additionally, and most importantly, position papers are solicited for short presentation and discussion of preliminary work or ideas. Submit a proposal of up to 2 pages, with a decision expected 2 weeks after submission.</p>
<p>The 1-day workshop will be co-located with ICME, the flagship multimedia conference sponsored by four IEEE societies. The workshop will be a unique opportunity to interact with other researchers working on 3D Multimedia. With an environment designed to facilitate discussion and feedback in early stage research, as well as forge new collaboration, this is an event not to be missed.</p>
<h4 class='specsess-heading'>Website</h4>
<a href='http://www.hot3d.org'>http://www.hot3d.org</a>
<h4 class='specsess-heading'>Workshop Chair</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Ioan&#32;Tabus-29dfb1837ad42d33dcc63895dc3c2286b99ce7c699e5f1ca7854d4293a704952.jpg'>
</div>
<div class='row oc-name'>
Ioan Tabus, Finland
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Zahir&#32;Alpaslan-672ec1cff9b24dd0f0436f8d3a145d441dd74efd70182aa2501b7e7bfe380017.jpg'>
</div>
<div class='row oc-name'>
Zahir Alpaslan, USA
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Touradj&#32;Ebrahimi-5d1bd2d0bd3bf471d7d77830a230710bc220a0c42c08cc09cdee150dfdf7671e.jpg'>
</div>
<div class='row oc-name'>
Touradj Ebrahimi, Switzerland
<br>
</div>
</div>
<div class='row'></div>

</div>
</div>
</div>
<div class='panel panel-primary'>
<div class='panel-heading'>
<h4 class='panel-title'>
<a data-parent='#accordion' data-toggle='collapse' href='conf_workshops.html#workshop-mast'>
Multimedia Analytics for Societal Trends
</a>
<span class='glyphicon glyphicon-link pull-right clickable-workshop-link' ldata='workshop-mast'></span>
</h4>
</div>
<div class='panel-collapse collapse' id='workshop-mast'>
<div class='panel-body'>
<h4 class='specsess-heading'>Monday, July 23, 2018 1:30PM - 5:00 PM. Room: N/A</h4>
<table class='table table-bordered'>
<tr>
<th>Time</th>
<th>Event</th>
</tr>
<tr>
<td>13:30</td>
<td>
<b>Opening remarks</b>
</td>
</tr>
<tr>
<td>13:45</td>
<td>
<b>Marginalized Identities in Entertainment Media</b>
<br>Dr. Caroline Heldman, Occidental College, LA</br>
<br>Dr.Nicole Haggard, Mount Saint Mary’s University, LA</br>
</td>
</tr>
<tr>
<td>14:25</td>
<td>
<b>Measuring the culture: Using Data Science to understand what drivespopularity</b>
<br>Dr. Carlos Ariza, Creative Artists’ Agency</br>
</td>
</tr>
<tr>
<td>15:00</td>
<td>
<b>Coffee Break</b>
</td>
</tr>
<tr>
<td>15:30</td>
<td>
<b>Protest Activity Detection and Violence Estimation from Twitter Images</b>
<br>Prof. Jungseock Joo, Department of Communication, UCLA</br>
</td>
</tr>
<tr>
<td>15:50</td>
<td>
<b>A Pilot Study in Deriving Political Stance Representation with User's Media Data and Social Links</b>
<br>Prof. Chi-Chun (Jeremy) Lee, National Tsing-Hua University, Taiwan</br>
</td>
</tr>
<tr>
<td>16:15</td>
<td>
<b>Panel discussion</b>
</td>
</tr>
</table>
<h4 class='specsess-heading'>Overview</h4>
<p>The widespread reach of media has extended beyond movies and ads to internet-based platforms that share user-generated images and videos. While automated analysis is indispensable for traditional multimedia areas i.e. navigating, indexing and organizing diverse and vast media databases, more recently, an emerging trend in this area has been to improve and facilitate personal and social activities, insight generation, and interaction experience. Research effort has been directed towards developing computational tools and methodologies for systematic study of trends and biases in commercially produced media forms, such as movies. Yet another emerging area involves studying the impact of such content on the end users.</p>
<p>One of the major research challenges in this area is that at the core of reliable analytics lie reliable algorithms. These algorithms must be robust under a diverse set of synthesized yet seemingly realistic background conditions. Depending on the type of media, these conditions could manifest themselves in the audio or video channels and could even vary within the duration of the content, thereby making it challenging to apply off-the-shelf techniques from other domains. Analysis of such content necessitates the design and training of customized algorithms that seek to exploit specific properties of or additional structure in the data. Infact, for most vision or audio related tasks, produced media data proves to be one of the most difficult benchmarks. This issue is further compounded by absence of any large in-domain datasets with reliable annotations.</p>
<p>As a result, research in this field often requires a mix of clever data mining techniques and approaches from semi-supervised or transfer learning. Finally, this research area is also becoming exceedingly multi-disciplinary requiring skills from a variety of fields including engineering, film studies, psychology and social sciences. Thus the main purpose of this workshop is to facilitate conversation between different groups of researchers and provide a platform where they can share progress and updates in recent research on media analytics for societal trends.</p>
<h4 class='specsess-heading'>Call for Papers</h4>
<p>
The workshop will offer a timely dissemination of research updates to benefit the academic and industry researchers and professionals working in the fields ranging from multimedia computing, multimodal signal processing to social science. To this end, we solicit original research papers related (but not limited) to the topics listed below:
<ul>
<li>Media analytics and methodologies for all forms of media.(e.g. automated discovery of rich analytics related to gender, profession, ethnicity, personality, stereotypes, topics of discussion/conversation, and analysis of their interrelationships, dynamics and evolution over time.)</li>
<li>Impact prediction and analysis (e.g. popularity, virality, memorability, commercial success and influence of media content on society)</li>
<li>Methodologies and analytics for analyzing relatively less-studied media, such as, advertisements and animated movies.</li>
<li>Affect and sentiment analysis from media (e.g. emotional appeal, persuasiveness, emotion perception and communication)</li>
<li>Large-scale data collection, benchmarking and challenges.</li>
<li>Evaluation protocols and metrics for methods analyzing societal trends.</li>
</ul>
</p>
<h4 class='specsess-heading'>Submission Instructions</h4>
<p>Papers will be evaluated based on their novelty, presentation, contributions and relevance to the workshop topic. The papers must be written in English and describe original unpublished work. Extensions on previously published work must show significant additional work in order to be considered for publication. Reviewers will make an initial determination on the suitability and scope of all submissions.</p>
<h4 class='specsess-heading'>Website</h4>
<a href='http://sail.usc.edu/mica/mast.html'>http://sail.usc.edu/mica/mast.html</a>
<h4 class='specsess-heading'>Workshop Chair</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Naveen&#32;Kumar-b95edaf567b77f0259f76d49fbbc6f1710c18fb2a7f8b7975de53fc47aa63261.jpg'>
</div>
<div class='row oc-name'>
Naveen Kumar, Sony Interactive Entertainment
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Tanaya&#32;Guha-5daca93d4c194217b1b0f0b534406637aa86f111a50c5acc9da8f5afd7419a39.jpg'>
</div>
<div class='row oc-name'>
Tanaya Guha, Dept. of Electrical Engineering Indian Institute of Technology, Kanpur
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Krishna&#32;Somandepalli-f6a06a1606d622af33486b538b85b0d5cee51f5c66e58e5cfcb70ba4b449bf2a.jpg'>
</div>
<div class='row oc-name'>
Krishna Somandepalli, Signal Analysis and Interpretation Laboratory University of Southern California
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Shri&#32;Narayanan-d0bfca68864b4c155c383593332332dd72a9672c52ee39f8abf53492fe90ea35.jpg'>
</div>
<div class='row oc-name'>
Shri Narayanan, Signal Analysis and Interpretation Laboratory University of Southern California
<br>
</div>
</div>
<div class='row'></div>

</div>
</div>
</div>
<div class='panel panel-primary'>
<div class='panel-heading'>
<h4 class='panel-title'>
<a data-parent='#accordion' data-toggle='collapse' href='conf_workshops.html#workshop-msts'>
Multimedia Services and Technologies for Smart-Health
</a>
<span class='glyphicon glyphicon-link pull-right clickable-workshop-link' ldata='workshop-msts'></span>
</h4>
</div>
<div class='panel-collapse collapse' id='workshop-msts'>
<div class='panel-body'>
<h4 class='specsess-heading'>Overview</h4>
<p>Today multimedia services and technologies play an important role in providing and managing e-health services to anyone, anywhere and anytime seamlessly. These services and technologies facilitate doctors and other healthcare professionals to have immediate access to e-health information for efficient decision making as well as better treatment. Researchers are working in developing various multimedia tools, techniques, and services to better support e-health initiatives. In particular, works in e-health record management, elderly health monitoring, real-time access of medical images and video are of great interest. Today multimedia services and technologies play an important role in providing and managing smart health services to anyone, anywhere and anytime seamlessly. These services and technologies facilitate doctors and other healthcare professionals to have immediate access to smart -health information for efficient decision making as well as better treatment. Researchers are working in developing various multimedia tools, techniques, and services to better support smart -health initiatives. In particular, works in smart-health record management, elderly health monitoring, real-time access to medical images and video are of great interest.</p>
<p>
This workshop aims to report high-quality research on recent advances in various aspects of smart-health, more specifically to the state-of- the-art approaches, methodologies, and systems in the design, development, deployment and innovative use of multimedia services, tools and technologies for health care. Authors are solicited to submit complete unpublished papers in the following, but not limited to:
<ul>
<li>Serious Games for smart health</li>
<li>Multimedia big data for healthcare applications</li>
<li>Digital Game-based Therapy</li>
<li>Adaptive exergames for smart health</li>
<li>Multimedia Enhanced Learning, Training &amp; Simulation for Health</li>
<li>Sensor and RFID technologies for smart health</li>
<li>Cloud-based smart health services</li>
<li>Resource allocation for media cloud-assisted smart healthcare</li>
<li>Multimedia big data for smart healthcare</li>
<li>Health record management</li>
<li>Context-aware smart health services and applications</li>
<li>Elderly health monitoring</li>
<li>Collaborative smart –health</li>
<li>IoT-Cloud Integration for Smart Healthcare</li>
<li>Deep learning approach for smart healthcare</li>
<li>Cloud-based connected healthcare</li>
<li>Security, privacy and authentication for Smart Healthcare Systems</li>
</ul>
</p>
<p>Extended versions of some selected accepted papers will be invited to submit to a special issue of an ISI journal and IEEE Access -Mobile Multimedia for Healthcare</p>
<h4 class='specsess-heading'>Website</h4>
<a href='http://www.mcrlab.net/must-sh-workshop/'>http://www.mcrlab.net/must-sh-workshop</a>
<h4 class='specsess-heading'>Workshop Chair</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/user_placeholder-8adfd14e5cbd3bb2fd5ad84744c0dad76fa94e959bcdf22dfc60bc0e9f7426e5.jpg'>
</div>
<div class='row oc-name'>
M. Shamim Hossain
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Stefan&#32;Gobel-ab73da5f94a74890026e3000848876f060e12f2da8c94e7b5d984c3d32921ac4.jpg'>
</div>
<div class='row oc-name'>
Stefan Goebel
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Abdurrahman&#32;Gobel-3e867490f6c020c8e92e0e1c40803147a9259b3a806af3f8a31ff9c69625f6f9.jpg'>
</div>
<div class='row oc-name'>
Abdur Rahman
<br>
</div>
</div>
<div class='row'></div>

</div>
</div>
</div>
<div class='panel panel-primary'>
<div class='panel-heading'>
<h4 class='panel-title'>
<a data-parent='#accordion' data-toggle='collapse' href='conf_workshops.html#workshop-mmc'>
Mobile Multimedia Computing
</a>
<span class='glyphicon glyphicon-link pull-right clickable-workshop-link' ldata='workshop-mmc'></span>
</h4>
</div>
<div class='panel-collapse collapse' id='workshop-mmc'>
<div class='panel-body'>
<h4 class='specsess-heading'>Overview</h4>
<p>The intimate presence of mobile devices in our daily life, such as smartphones and various wearable gadgets like smart watches, has dramatically changed the way we connect with the world around us. Nowadays, in the era of the Internet‐of‐Things (IoT), these devices are further extended by smart sensors and actuators and amend multimedia devices with additional data and possibilities. With a growing number of powerful embedded mobile sensors like camera, microphone, GPS, gyroscope, accelerometer, digital compass, and proximity sensor, there is a variety of data available and hence enables new sensing applications across diverse research domains comprising mobile media analysis, mobile information retrieval, mobile computer vision, mobile social networks, mobile human‐computer interaction, mobile entertainment, mobile gaming, mobile healthcare, mobile learning, and mobile advertising. Therefore, the workshop on Mobile Multimedia Computing (MMC 2018) aims to bring together researchers and professionals from worldwide academia and industry for showcasing, discussing, and reviewing the whole spectrum of technological opportunities, challenges, solutions, and emerging applications in mobile multimedia.</p>
<h4 class='specsess-heading'>Topics</h4>
<p>
<ul>
<li>Ubiquitous computing on mobile and wearable devices</li>
<li>Action/gesture/object/speech recognition with mobile sensor</li>
<li>Computational photography on mobile devices</li>
<li>Human computer interaction with mobile and wearable devices</li>
<li>Mobile multimedia content adaptation and adaptive streaming</li>
<li>Power saving issues of mobile multimedia computing</li>
<li>Personalization, privacy and security in mobile multimedia</li>
<li>User behavior analysis of mobile multimedia applications</li>
<li>Other topics related to mobile multimedia computing</li>
<li>Mobile visual search</li>
<li>Multimedia data in the IoT</li>
<li>Mobile social signal processing</li>
<li>Mobile virtual and augmented reality</li>
<li>Mobile multimedia indexing and retrieval</li>
<li>Multi‐modal and multi‐user mobile sensing</li>
<li>2D/3D computer vision on mobile devices</li>
<li>Multimedia Cloud Computing</li>
</ul>
</p>
<h4 class='specsess-heading'>Website</h4>
<p>
<a href='http://mclab.citi.sinica.edu.tw/open/mmc2018/'>http://mclab.citi.sinica.edu.tw/open/mmc2018/</a>
</p>
<h4 class='specsess-heading'>Workshop Chair</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Wen-Huang&#32;Cheng-9038e81557285e25f56605a819277a513f8d850bf08ec18f55ecf30e188469fb.jpg'>
</div>
<div class='row oc-name'>
Wen-Huang Cheng, Academia Sinica, Taiwan
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Kai-Lung&#32;Hua-fd98856645db09062acc7c67ce4ef5bdc69b5b6c020bd9d50c5182f62e100d10.jpg'>
</div>
<div class='row oc-name'>
Kai-Lung Hua, National Taiwan University of Science and Technology, Taiwan
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Klaus&#32;Schoeffmann-77ad9dc3417b42e4302218ed01b1cb1b0c0f869230daca943e5bab6170f5c116.jpg'>
</div>
<div class='row oc-name'>
Klaus Schoeffmann, Klagenfurt University, Austria
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Tian&#32;Gan-fd17d698a893b80c8df07f750b8a825f08c14cb3af4b866c371ca6e0ac982ea0.jpg'>
</div>
<div class='row oc-name'>
Tian Gan, Shandong University, China
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Christian&#32;Weth-58cf3c7e7b44af44adeec7d657d596e9670e9151dea7230ca50db4836b8dcf80.jpg'>
</div>
<div class='row oc-name'>
Christian von der Weth, National University of Singapore, Singapore
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Marta&#32;Mrak-7b9e1c27e6ec2f048dafa36d102f439e832bb163bc66f24cbb76e7c06802ae65.jpg'>
</div>
<div class='row oc-name'>
Marta Mrak, BBC R&amp;D, UK
<br>
</div>
</div>
<div class='row'></div>

</div>
</div>
</div>
<div class='panel panel-primary'>
<div class='panel-heading'>
<h4 class='panel-title'>
<a data-parent='#accordion' data-toggle='collapse' href='conf_workshops.html#workshop-mlaim'>
Machine Learning and Artificial Intelligence for Multimedia Creation
</a>
<span class='glyphicon glyphicon-link pull-right clickable-workshop-link' ldata='workshop-mlaim'></span>
</h4>
</div>
<div class='panel-collapse collapse' id='workshop-mlaim'>
<div class='panel-body'>
<h4 class='specsess-heading'>Overview</h4>
<p>This workshop focuses on the emerging field of multimedia creation using machine learning (ML) and artificial intelligence (AI) approaches. It aims to bring together researchers from ML and AI and practitioners from multimedia industry to foster multimedia creation. Multimedia creation, including style transfer and image synthesis, have been a major focus of machine learning and AI societies, owing to the recent technological breakthroughs such as generative adversarial networks (GANs). This workshop seeks to reinforce the implications to multimedia creation. It publishes papers on all emerging areas of content understanding and multimedia creation, all traditional areas of computer vision and data mining, and selected areas of artificial intelligence, with a particular emphasis on machine learning for pattern recognition. The applied fields such as art content creation, medical image and signal analysis, massive video/image sequence analysis, facial emotion analysis, control system for automation, content-based retrieval of video and image, and object recognition are also covered. The workshop is expected to provide an interactive platform to researchers, scientists, professors, and students to exchange their innovative ideas and experiences in the areas of Multimedia, and to specialize in the field of multimedia from underlying cutting-edge technologies to applications.</p>
<h4 class='specsess-heading'>Topics</h4>
<p>
<ul>
<li>Generative models for multimedia creation</li>
<li>AI for multimedia creation</li>
<li>Data mining techniques for multimedia creation</li>
<li>Synthesis and prediction of multimedia</li>
<li>Deep learning application in video and image analysis</li>
<li>Multi-modal data analysis</li>
<li>Medical image and signal analysis</li>
<li>Content of video and image extraction, analysis and application</li>
<li>Online and distributed computing for multimedia creation</li>
<li>Wireless technology and demonstrations for multimedia creation</li>
<li>Security, privacy and policy regulation for multimedia creation</li>
<li>Machine learning on social, emotional and affective multimedia</li>
<li>Augmented reality</li>
<li>Multimedia applied on control system for automation</li>
<li>Human-computer interaction</li>
<li>Signal processing including audio, video, image processing, and coding</li>
<li>Smart multimedia surveillance</li>
</ul>
</p>
<p>
For more details, please refer to the submission instruction of ICME 2018
<a href='author_info.html'>here.</a>
</p>
<h4 class='specsess-heading'>Website</h4>
<a href='https://hellomlai2017.github.io/'>https://hellomlai2017.github.io/</a>
<h4 class='specsess-heading'>Workshop Chair</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Yanjia&#32;Sun-b769d2c4a8e11d0933cbb6d1148b62394d606581f02f0a659b21c789739b03fd.jpg'>
</div>
<div class='row oc-name'>
Yanjia Sun, PhD, Principal Data Scientist, ADP, LLC
<br>
<a href='mailto:yanjia.sun@adp.com'>
<span class='oc-email'>yanjia.sun@adp.com</span>
</a>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Sijia&#32;Liu-8e1e952f6c02085bb9293ba89451a365f7a6b515965a8921ffb9edb1a73aa964.jpg'>
</div>
<div class='row oc-name'>
Sijia Liu, Postdoctoral Research Fellow, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, USA
<br>
<a href='mailto:lsjxjtu@umich.edu'>
<span class='oc-email'>lsjxjtu@umich.edu</span>
</a>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Pin-Yu&#32;Chen-8134b00a0e5c6f206be4cb97f6ddf701ebfe5457e2595701598bb9ea8be19220.jpg'>
</div>
<div class='row oc-name'>
Pin-Yu Chen, PhD, Research Staff Member, AI Foundations Group, IBM T. J. Watson Research Center
<br>
<a href='mailto:pin-yu.chen@ibm.com'>
<span class='oc-email'>pin-yu.chen@ibm.com</span>
</a>
</div>
</div>
<div class='row'></div>

</div>
</div>
</div>
<div class='panel panel-primary'>
<div class='panel-heading'>
<h4 class='panel-title'>
<a data-parent='#accordion' data-toggle='collapse' href='conf_workshops.html#workshop-pim'>
Privacy Issues in Multimedia
</a>
<span class='glyphicon glyphicon-link pull-right clickable-workshop-link' ldata='workshop-pim'></span>
</h4>
</div>
<div class='panel-collapse collapse' id='workshop-pim'>
<div class='panel-body'>
<h4 class='specsess-heading'>Overview</h4>
<p>The past decade has seen a tremendous growth in multimedia systems and applications in various areas ranging from surveillance to social media. While these systems and applications have been instrumental in improving the way of life for the end users; in the process the people's privacy might be put at risk. In particular, in most social networking websites, users upload their information without any guarantees on privacy. Although there has been a significant progress in multimedia research, the issues related to privacy related to the use of multimedia systems and applications have only recently begun to attract the attention of researchers.</p>
<p>
This is the second edition of this workshop (after the first successful PIM’16 in Seattle) and it aims to bring forward recent advances related to privacy protection in various multimedia systems and applications. We seek unpublished high quality papers that address the privacy issues in different multimedia applications including, but not limited to, surveillance, e-chronicles, e-health, mobile media, and social networking from the following perspectives:
<ul>
<li>Privacy considerations in acquisition and transmission of multimedia data.</li>
<li>Privacy issues in fusion, analysis, presentation, and publication of multimedia data.</li>
<li>Privacy in multimedia databases: storage, access, indexing and retrieval.</li>
<li>Theory and models: assessment of security and privacy and utility, privacy leakage and covert channels.</li>
<li>Synergy between privacy preserving technologies and ethical and legal issues.</li>
<li>Privacy aware cloud-based multimedia storage and processing.</li>
<li>System architectural choices for privacy preservation.</li>
</ul>
</p>
<h4 class='specsess-heading'>Website</h4>
<a href='http://www.cs.albany.edu/~patrey/pim18/'>http://www.cs.albany.edu/~patrey/pim18/</a>
<h4 class='specsess-heading'>Workshop Chair</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Pradeep&#32;Atrey-d4588c781416eda344bd8ae6c48ae6f00cf4ef4786a455c13a69fc5cd7d333e4.jpg'>
</div>
<div class='row oc-name'>
Pradeep Atrey, State University of New York, Albany, USA
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Samson&#32;Cheung-7be16306af69ac47196fef2a2e5e3f6701851ea3c1109550e4b99a69371b0e34.jpg'>
</div>
<div class='row oc-name'>
Sen-cheng &#39;Samson&#39; Cheung, Univeristy of Kentucky, USA
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Frederic&#32;Dufaux-5fb3a3c3e81026de703c491122567a7cee5940149fe12269337bb8d218d11507.jpg'>
</div>
<div class='row oc-name'>
Frederic Dufaux, CNRS and Telecom ParisTech, France
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Andrea&#32;Cavallaro-92f3bb3f77042b85e8b1bc6286ca64a6a2f9c4d6f4d54e7b78b8e5c3d2ed364d.jpg'>
</div>
<div class='row oc-name'>
Andrea Cavallaro, Queen Mary University of London, UK
<br>
</div>
</div>
<div class='row'></div>

</div>
</div>
</div>
<div class='panel panel-primary'>
<div class='panel-heading'>
<h4 class='panel-title'>
<a data-parent='#accordion' data-toggle='collapse' href='conf_workshops.html#workshop-emsa'>
Emerging Multimedia Systems and Applications
</a>
<span class='glyphicon glyphicon-link pull-right clickable-workshop-link' ldata='workshop-emsa'></span>
</h4>
</div>
<div class='panel-collapse collapse' id='workshop-emsa'>
<div class='panel-body'>
<h4 class='specsess-heading'>Overview</h4>
<p>
Recent years have witness a great popularity of multimedia applications and services. With the rapid growth of the volume of multimedia data and the complexity of systems, high efficient processing and analytics technologies have received significant attention and become key research issues. This workshop is intended to promote further research interests and activities related to multimedia data processing and analytics as well as to provide a forum for researchers and engineers to present their cutting-edge innovations and share their experiences on all aspects of the emerging multimedia systems and applications. Topics of interests include, but are not limited to:
<ul>
<li>Theories and methodologies for multimedia big data computing</li>
<li>High efficient multimedia data compression and transmission</li>
<li>Multimedia retrieval, classification and understanding</li>
<li>Security and privacy in multimedia big data</li>
<li>Multimedia quality of experience</li>
<li>Multimedia big data systems</li>
<li>Multi-modality fusion of multimedia content</li>
<li>Object localization and recognition in images/videos</li>
<li>VR/AR content generation and analysis</li>
<li>Syntactic parsing and semantic analysis</li>
<li>Machine translation and speech recognition</li>
<li>Word segmentation and text mining</li>
<li>Question answering and user interaction</li>
<li>Benchmark datasets of emerging multimedia applications</li>
<li>Tutorials/surveys of the advances of multimedia technologies</li>
</ul>
</p>
<h4 class='specsess-heading'>Website</h4>
<a href='http://2018-icme-w8.github.io'>2018-icme-w8.github.io</a>
<h4 class='specsess-heading'>Workshop Chair</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Philip&#32;Chen-616d7801363c448af42c08d5c4cc9f35a364aa86188b71c5cc04920d76d0870a.jpg'>
</div>
<div class='row oc-name'>
Philip Chen, University of Macau, Macau
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Zhenzhong&#32;Chen-e4726a146396878fce952aa13900847381b901cee32142aff417beaebd5e36c2.jpg'>
</div>
<div class='row oc-name'>
Zhenzhong Chen, Wuhan University, China
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Chenwei&#32;Deng-14cadf0615ea0fb30282796c39037a53d0d9c300f0678b1be1cab6b538f740fe.jpg'>
</div>
<div class='row oc-name'>
Chenwei Deng, Beijing Institute of Technology, China
<br>
</div>
</div>
<div class='row'></div>

</div>
</div>
</div>
<div class='panel panel-primary'>
<div class='panel-heading'>
<h4 class='panel-title'>
<a data-parent='#accordion' data-toggle='collapse' href='conf_workshops.html#workshop-fim'>
Faces in Multimedia
</a>
<span class='glyphicon glyphicon-link pull-right clickable-workshop-link' ldata='workshop-fim'></span>
</h4>
</div>
<div class='panel-collapse collapse' id='workshop-fim'>
<div class='panel-body'>
<h4 class='specsess-heading'>Overview</h4>
<p>We have witnessed remarkable advances in facial recognition technologies over the past a few years due to the rapid development of deep learning and large-scale, labeled facial image collections. As progress continues to push renown facial recognition databases nearly to saturation. There is a need for evermore challenging image and video collections, to solve emerging problems in the fields of faces and multimedia.</p>
<p>In parallel to conventional face recognition, research is done to automatically understand social media content. To gain such an understand, the following capabilities must be satisfied: face tracking (e.g., facial expression analysis, face detection), face characterization (e.g., behavioral understanding, emotion recognition), facial characteristic analysis (e.g., gait, age, gender and ethnicity recognition), group understanding via social cues (e.g., kinship, non-blood relationships, personality), and visual sentiment analysis (e.g., temperament, arrangement). The ability to create effective models for visual certainty has significant value in both the scientific communities and the commercial market, with applications that span topics of human-computer interaction, social media analytics, video indexing, visual surveillance, and Internet vision.</p>
<p>This workshop serves a forum for researchers to review the recent progress of recognition, analysis and modeling of faces in multimedia. Special interests will be given to visual kin and non-kin social relations. The workshop will include up to two keynotes, along with peer-reviewed papers (oral and poster). Original high-quality contributions are solicited on the topics listed in the section below.</p>
<h4 class='specsess-heading'>Topics</h4>
<ul>
<li>Soft biometrics and profiling of faces: age, gender, ethnicity, personality, kinship, occupation, and beauty ranking;</li>
<li>Deep learning practice for social face problems with ambiguity including kinship</li>
verification, family recognition and retrieval;
<li>Understanding of the familial features from vast amount of social media data;</li>
<li>Discovery of the social groups from faces and the context;</li>
<li>Mining social face relations through metadata as well as visual information;</li>
<li>Tracking and extraction and analysis of face models captured by mobile devices;</li>
<li>Face recognition in low-quality or low-resolution video or images;</li>
<li>Novel mathematical models and algorithms, sensors and modalities for face &amp;</li>
body gesture and action representation;
<li>Analysis and recognition for cross-domain social media;</li>
<li>Novel social applications involving detection, tracking &amp; recognition of faces;</li>
<li>Face analysis for sentiment analysis in social media;</li>
<li>Other applications involving face analysis in social media content.</li>
</ul>
<h4 class='specsess-heading'>Honorary General Chair</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Thomas&#32;Huang-04247eba4b8007a693fcca9f0280383393e8cac6ddbc5c9b8d70f64fe705189f.jpg'>
</div>
<div class='row oc-name'>
Thomas S. Huang, University of Illinois at Urbana-Champaign, USA
<br>
</div>
</div>
<div class='row'></div>

<h4 class='specsess-heading'>General Chair</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Raymond&#32;Fu-559d3d00365049c61cfbd8d073b6a63f0eee2a56bba564dee691e6199ca41857.jpg'>
</div>
<div class='row oc-name'>
Y. Raymond Fu, Northeastern University, Boston, USA
<br>
</div>
</div>
<div class='row'></div>

<h4 class='specsess-heading'>Program Chairs</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Joseph&#32;Robinson-972f50f037417afd442c79b32fdf84022505e05c6d92653a042f3a233b588f56.jpg'>
</div>
<div class='row oc-name'>
Joseph P. Robinson, Northeastern University, Boston, USA
<br>
<a href='mailto:robinson.jo@husky.neu.edu'>
<span class='oc-email'>robinson.jo@husky.neu.edu</span>
</a>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Ming&#32;Shao-7f7352be41fd27487f62c0400fede31e7d55bdb57cd6d031a9a4d8fd70907e7d.jpg'>
</div>
<div class='row oc-name'>
Ming Shao, University of Massachusetts Dartmouth, USA
<br>
<a href='mailto:mshao@umassd.edu'>
<span class='oc-email'>mshao@umassd.edu</span>
</a>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Siyu&#32;Xia-5930e373f5af1f5ab1af3db6ce813a25c87b85b1b8d89953d64720fdf98045e6.jpg'>
</div>
<div class='row oc-name'>
Siyu Xia, Southeast University, China
<br>
<a href='mailto:xia081@gmail.com'>
<span class='oc-email'>xia081@gmail.com</span>
</a>
</div>
</div>
<div class='row'></div>

</div>
</div>
</div>
<div class='panel panel-primary'>
<div class='panel-heading'>
<h4 class='panel-title'>
<a data-parent='#accordion' data-toggle='collapse' href='conf_workshops.html#workshop-mbl'>
Multimodal Biometrics Learning
</a>
<span class='glyphicon glyphicon-link pull-right clickable-workshop-link' ldata='workshop-mbl'></span>
</h4>
</div>
<div class='panel-collapse collapse' id='workshop-mbl'>
<div class='panel-body'>
<h4 class='specsess-heading'>Overview</h4>
<p>Biometrics based recognition, identification and retrieval techniques become more and more important in our society. Great progress has been made in this area, focusing on heterogeneous cues (face, body (2D appearance and 3D volume), other unimodal biometrics such as finger and palm, gait, behavioral cues in general) which do not require user’s collaboration. However, this problem is far from being completely solved, particularly in real-world applications under uncontrolled environments, where a large number of factors hinder the identification/recognition/retrieval performance, including lighting variations, different types of occlusion, large pose evaluation and view change etc.</p>
<p>The mission of the workshop is to explore the cutting-edge research in non-collaborative (re)identification/recognition/retrieval, with a particular emphasis on the fusion of different modalities under cross-view setting. For example, the face recognition and the re-identification communities, even though they share many objectives, they rarely have interacted to hybridize novel recognition applications, where both the biometric patterns face and body can be jointly exploited. This holds true also for the communities of gait recognition and body re-identification, thermal body recognition, visual body recognition and other biometrics cues such as Iris Recognition at a distance. The workshop, in this sense, will be highly interdisciplinary, encouraging papers (even preliminary), where the modality fusion plays a primary role.</p>
<p>In addition, human-related identification/recognition/retrieval techniques greatly rely on the development of feature and similarity learning strategy. Therefore, this workshop also aims to explore recent progress in feature and similarity learning (distance metric learning) for biometric based identification/recognition/retrieval. It has been observed in recent years that the (re-)identification identification/recognition/retrieval performance can be largely improved when a robust feature representation or an appropriate distance/similarity function have been learned. In this aspect, this workshop will help the community to better understand the challenges and opportunities of feature and similarity learning techniques and their applications to (re-)identification for the next few years. In addition, with the great increasing number of data, the techniques addressing the large- scale biometrics are also extremely required.</p>
<h4 class='specsess-heading'>Topics & Format</h4>
Topics of interest include, but are not limited to:
<ul>
<li>Face, Finger, Iris, Palm Recognition.</li>
<li>Person Re-identification.</li>
<li>People Detection, Tracking, and Gait analysis.</li>
<li>Novel biometrics sensing methods and Soft Biometrics.</li>
<li>Feature Learning for Biometrics Recognition.</li>
<li>Similarity Learning (Distance Metric Learning) for Biometrics Recognition.</li>
<li>Human identification with multiple cues and multi-modality fusion.</li>
<li>Large scale search and matching for identification.</li>
<li>Transfer Learning for visual surveillance.</li>
<li>Performance modeling, prediction and evaluation of identification/biometrics systems.</li>
<li>Security improvement assessment for multi-identification/biometrics systems.</li>
<li>Large scale multi-biometrics feature learning for fast retrieval.</li>
<li>Hash learning for biometrics.</li>
</ul>
<p>We propose to host a half day workshop consisting of oral presentations, an invited speech and a panel.</p>
<h4 class='specsess-heading'>Workshop Chairs</h4>
<h3></h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Weishi&#32;Zheng-bf17a5193ee4e1c4cd8a5dafd95f68fedbd83cdc1e9913041c0b18b85e935f88.jpg'>
</div>
<div class='row oc-name'>
Wei-Shi Zheng, Sun Yat-sen University, China
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Cairong&#32;Zhao-831039e60b6159452f01d722a98eb35be64c5eadcd2ab3505ddf0374a2d60aee.jpg'>
</div>
<div class='row oc-name'>
Cairong Zhao, Tongji University, China
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Zhihui&#32;Lai-8f7d66bed09c2604f2cd8eae1fba4867c17506fcf6b3e93352b4e0ed4a47c4e7.jpg'>
</div>
<div class='row oc-name'>
Zhihui Lai, Shen Zhen University, China
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/user_placeholder-8adfd14e5cbd3bb2fd5ad84744c0dad76fa94e959bcdf22dfc60bc0e9f7426e5.jpg'>
</div>
<div class='row oc-name'>
Yang Yang, UESTC, China
<br>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Zhihua&#32;Wei-95fac3c24083577db6faefad21c9f1972be457b325215299dbc06e0939559d2c.jpg'>
</div>
<div class='row oc-name'>
Zhihua Wei, Tongji University, China
<br>
</div>
</div>
<div class='row'></div>

</div>
</div>
</div>
</div>
<h4 class='specsess-heading'>Paper Submission Instructions</h4>
<p>
Please submit a full-length paper (up to 6 pages IEEE 2-column format) through the online submission system
<a href='https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FICME2018W'>here</a>
</p>
<p>
The templates for Microsoft Word and LaTeX submissions are available as below.
<ul>
<li>
8.5" x 11" Word template downloadable from
<a href='assets/icme2018template-a950264319d84bd5675833d2b564d29c1eb2e05738f8ee56e58b705467ce60c2.docx'>here</a>
</li>
<li>
LaTeX formatting macros downloadable from
<a href='assets/icme2018template-607e2f9a81f353139e5c3a7a7c7b24d685b12df1d71d81b26bb06a894cfd8340.zip'>here</a>
</li>
</ul>
</p>
<h3>Important Dates</h3>
<ul>
<li>
Workshop Paper
submission deadline:
<span class='extended-date'>March 19, 2018</span>
<span class='extended-new-date'>
(Extended
March 26, 2018
)
</span>
</li>
<li>
Workshop Paper
acceptance
notification: April 27, 2018
</li>
<li>
Camera-Ready Workshop Paper
submission deadline:
May 11, 2018
</li>
</ul>

<h3>Workshop Chairs</h3>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Mohan&#32;Kankanhalli-388bfa7846f50732d141e20509ab41f83c8eeb52eac70c7b57970189ad9dc835.jpg'>
</div>
<div class='row oc-name'>
Mohan Kankanhalli, NUS, Singapore
<br>
<a href='mailto:mohan@comp.nus.edu.sg'>
<span class='oc-email'>mohan@comp.nus.edu.sg</span>
</a>
</div>
</div>
<div class='col-xs-6 col-sm-4 col-lg-3 oc-cell'>
<div class='row'>
<img class='oc-photo' src='assets/photos/Kai&#32;Yang-abdc3c12f01db0c7e91da49da0aa75ce14676b3dffff38c3cb4fa2a6cc87ca53.jpg'>
</div>
<div class='row oc-name'>
Kai Yang, Tongji University, China
<br>
<a href='mailto:kaiyang@tongji.edu.cn'>
<span class='oc-email'>kaiyang@tongji.edu.cn</span>
</a>
</div>
</div>
<div class='row'></div>

<!-- = javascript_include_tag 'layout_helper' -->
<script>
  $(document).ready(function() {
  	layout_helper.activate_hotlinked();
  })
</script>

</div>
<div class='container-fluid footer'>
ICME 2018
<br>
<div class='col-xs-12 sponsor-level'>
Platinum Sponsors
<div class='row'></div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/acer-980b2ec48c85c84468ffcdca75157b7e8ae3a76e48e40d1dca4b7ddf53975d0f.png" alt="Acer" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/adobe-a63348885355ccc271e65c77c8759a99f8e0d9577dad70b51f7eb16fdd1f160f.png" alt="Adobe" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/interdigital-f019cb2bde775cb812ad4ab9f2dfcee1a20e0224feecfee5290f83b5fb738813.png" alt="Interdigital" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/qualcomm-751cd13b960ecef28d6fcd415d905998571912a1f7ed8b50b332114ca7230dbe.png" alt="Qualcomm" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/tencent-fd3580d4fcbddb9e94bc6b8cf6a9642d9b8a403d325f33ee8ac01d0f572ce5f2.png" alt="Tencent" />
</div>
</div>
<div class='col-xs-12 sponsor-level'>
Gold Sponsors
<div class='row'></div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/huawei-b3f2d54b5dd33925c26e995dc5de0e4aee580262f070df11fc5fd732b049203d.png" alt="Huawei" />
</div>
</div>
<div class='col-xs-12 sponsor-level'>
Silver Sponsors
<div class='row'></div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/mediatek-52cfdf065c59f835fb4f5680e216757eb73f9bd76d0154c325637205db6bced6.png" alt="Mediatek" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/microsoft-4c5faae20b7a9f605770e53c777c3a49fa4e1d9ad63c145ed80a687da82cef50.png" alt="Microsoft" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/mitsubishi-ae78667c8a5d49431c2dcf906adadc54b450483750cbe2ec53c385fb31c7a295.png" alt="Mitsubishi" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/netflix-ca08065331a2cb3c9c1133f6edf4e122419fdfd829d4e4a688429e74380bd10d.png" alt="Netflix" />
</div>
</div>
<div class='col-xs-12 sponsor-level'>
Bronze Sponsors
<div class='row'></div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/lenovo-4a18ba59b975d0b62e384eef9c01dd09f1a43695d7b6641cd807c392fba9da59.png" alt="Lenovo" />
</div>
</div>
<div class='col-xs-12 sponsor-level'>
Organizational Sponsors
<div class='row'></div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/IEEE-0b3ec1c528ec07a813f6c67ebe93bf9e6398997b6eb0f92d977d2f6190eb6e3a.png" alt="Ieee" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/IEEE_CS-b388f6914d62d390019067e6d677be46800d79b26445ba8dcf7eee76b15b32f7.png" alt="Ieee cs" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/CAS-36dae780ab151e2e75199588e080bb08e52977b152267137b6ae3d7ad541d786.png" alt="Cas" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/ComSoc-63e54087b2df13eb129793cafda8692f19ae52988835c3776069fd37e8d277d6.png" alt="Comsoc" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/IEEE_SPS-d67ab43c7380cd1fa181dff6b5ebad7ee32fd40c7e8d397bb048406307fb919e.png" alt="Ieee sps" />
</div>
<div class='col-xs-12 col-sm-6 col-md-3 sponsor-container'>
<img class="sponsor-logo" src="assets/logos/apsipa-67e6014135cacaf352cc6959084ccd94babf077d1b6e6d26bf2024d9a496a0e1.png" alt="Apsipa" />
</div>
</div>
</div>
</body>
</html>
